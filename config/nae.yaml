experiment:
  mode: autoencoder
  
  model:
    network_name: nae
    latent_dim: 10
  
  training:
    n_epochs: 10
    batch_size: 128
    kl_strength: 1.e-3
    output_path: ./output/nae

  optimizer:
    optimizer_name: adam
    lr: 0.0001
    betas: [0.9, 0.999]
    eps: 1.e-7
    weight_decay: 1.e-4
    amsgrad: false

  seed: 42