{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT6NLA2Y5D07q5mVM/ow3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TSHP/DL4SC_Neural_ODEs/blob/main/ToyExampleTobia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading in the MNIST DATASET"
      ],
      "metadata": {
        "id": "rRAHnmmbuO8l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8i5pH33gtmv5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.nn import ReLU\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.functional import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnistTrainSet = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                    download=True, transform=transforms.ToTensor()) # might need to normalize\n",
        "mnistTrainLoader = torch.utils.data.DataLoader(mnistTrainSet, batch_size=64,\n",
        "                                      shuffle=True)"
      ],
      "metadata": {
        "id": "XM_wLT1XvDve",
        "outputId": "1b5d6ac0-2692-442f-b4b8-bc1076c9377a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 71342767.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 89796659.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 21952074.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 15035934.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constructing a 1 Layer MLP"
      ],
      "metadata": {
        "id": "_SV3fPbEvNCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear = nn.Linear(in_dim, out_dim)\n",
        "        self.Relu = ReLU()\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        out = self.Relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "UiO7GKtOvDzU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "in_dim, num_class = 28*28, 10\n",
        "\n",
        "l_r = 0.0001\n",
        "w_decay = 1e-4\n",
        "model = MLP(in_dim, num_class)\n",
        "optimizer = optim.Adam(model.parameters(), lr=l_r, weight_decay = w_decay)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "vszFzJ-Qvilu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with 10 class probabilities"
      ],
      "metadata": {
        "id": "4eYiV8XP6FQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(mnistTrainLoader)\n",
        "epochs = 10\n",
        "for cur_epoch in range(epochs):\n",
        "  for x, (images, labels) in enumerate(mnistTrainLoader):\n",
        "    images = images.reshape(-1, 28*28)\n",
        "\n",
        "    out = model(images)\n",
        "\n",
        "    losses = criterion(out, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses.backward()\n",
        "    optimizer.step()\n",
        "    if (x+1) % 300 == 0:\n",
        "      print (f'Epoch[{cur_epoch+1}/{epochs}], Step[{x+1}/{total_steps}], Losses: {losses.item():.4f}')\n",
        "print(losses.item())"
      ],
      "metadata": {
        "id": "ohQ17KWU1sis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader Understanding"
      ],
      "metadata": {
        "id": "C5fYLDqA03dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mnistTrainSet.data[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y-GwnLsivlC5",
        "outputId": "c1d47e1e-6b1e-4472-b1af-98cc849687ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcTUlEQVR4nO3df3DU9b3v8dcCyQqaLI0hv0rAgD+wAvEWJWZAxJJLSOc4gIwHf3QGvF4cMXiKaPXGUZHWM2nxjrV6qd7TqURnxB+cEaiO5Y4GE441oQNKGW7blNBY4iEJFSe7IUgIyef+wXXrQgJ+1l3eSXg+Zr4zZPf75vvx69Znv9nNNwHnnBMAAOfYMOsFAADOTwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGG9gFP19vbq4MGDSktLUyAQsF4OAMCTc04dHR3Ky8vTsGH9X+cMuAAdPHhQ+fn51ssAAHxDzc3NGjt2bL/PD7gApaWlSZJm6vsaoRTj1QAAfJ1Qtz7QO9H/nvcnaQFat26dnnrqKbW2tqqwsFDPPfecpk+ffta5L7/tNkIpGhEgQAAw6Pz/O4ye7W2UpHwI4fXXX9eqVau0evVqffTRRyosLFRpaakOHTqUjMMBAAahpATo6aef1rJly3TnnXfqO9/5jl544QWNGjVKL774YjIOBwAYhBIeoOPHj2vXrl0qKSn5x0GGDVNJSYnq6upO27+rq0uRSCRmAwAMfQkP0Geffaaenh5lZ2fHPJ6dna3W1tbT9q+srFQoFIpufAIOAM4P5j+IWlFRoXA4HN2am5utlwQAOAcS/im4zMxMDR8+XG1tbTGPt7W1KScn57T9g8GggsFgopcBABjgEn4FlJqaqmnTpqm6ujr6WG9vr6qrq1VcXJzowwEABqmk/BzQqlWrtGTJEl1zzTWaPn26nnnmGXV2durOO+9MxuEAAINQUgK0ePFi/f3vf9fjjz+u1tZWXX311dq6detpH0wAAJy/As45Z72Ir4pEIgqFQpqt+dwJAQAGoROuWzXaonA4rPT09H73M/8UHADg/ESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGG9AGAgCYzw/5/E8DGZSVhJYjQ8eElccz2jer1nxk885D0z6t6A90zr06neMx9d87r3jCR91tPpPVO08QHvmUtX1XvPDAVcAQEATBAgAICJhAfoiSeeUCAQiNkmTZqU6MMAAAa5pLwHdNVVV+m99977x0Hi+L46AGBoS0oZRowYoZycnGT81QCAISIp7wHt27dPeXl5mjBhgu644w4dOHCg3327uroUiURiNgDA0JfwABUVFamqqkpbt27V888/r6amJl1//fXq6Ojoc//KykqFQqHolp+fn+glAQAGoIQHqKysTLfccoumTp2q0tJSvfPOO2pvb9cbb7zR5/4VFRUKh8PRrbm5OdFLAgAMQEn/dMDo0aN1+eWXq7Gxsc/ng8GggsFgspcBABhgkv5zQEeOHNH+/fuVm5ub7EMBAAaRhAfowQcfVG1trT755BN9+OGHWrhwoYYPH67bbrst0YcCAAxiCf8W3KeffqrbbrtNhw8f1pgxYzRz5kzV19drzJgxiT4UAGAQS3iAXnvttUT/lRighl95mfeMC6Z4zxy8YbT3zBfX+d9EUpIyQv5z/1EY340uh5rfHk3znvnZ/5rnPbNjygbvmabuL7xnJOmnbf/VeybvP1xcxzofcS84AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE0n8hHQa+ntnfjWvu6ap13jOXp6TGdSycW92ux3vm8eeWes+M6PS/cWfxxhXeM2n/ecJ7RpKCn/nfxHTUzh1xHet8xBUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHA3bCjYcDCuuV3H8r1nLk9pi+tYQ80DLdd5z/z1SKb3TNXEf/eekaRwr/9dqrOf/TCuYw1k/mcBPrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNS6ERLa1xzz/3sFu+Zf53X6T0zfM9F3jN/uPc575l4PfnZVO+ZxpJR3jM97S3eM7cX3+s9I0mf/Iv/TIH+ENexcP7iCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSBG3jPV13jNj3rrYe6bn8OfeM1dN/m/eM5L0f2e96D3zm3+7wXsmq/1D75l4BOriu0Fogf+/WsAbV0AAABMECABgwjtA27dv10033aS8vDwFAgFt3rw55nnnnB5//HHl5uZq5MiRKikp0b59+xK1XgDAEOEdoM7OThUWFmrdunV9Pr927Vo9++yzeuGFF7Rjxw5deOGFKi0t1bFjx77xYgEAQ4f3hxDKyspUVlbW53POOT3zzDN69NFHNX/+fEnSyy+/rOzsbG3evFm33nrrN1stAGDISOh7QE1NTWptbVVJSUn0sVAopKKiItXV9f2xmq6uLkUikZgNADD0JTRAra2tkqTs7OyYx7Ozs6PPnaqyslKhUCi65efnJ3JJAIAByvxTcBUVFQqHw9GtubnZekkAgHMgoQHKycmRJLW1tcU83tbWFn3uVMFgUOnp6TEbAGDoS2iACgoKlJOTo+rq6uhjkUhEO3bsUHFxcSIPBQAY5Lw/BXfkyBE1NjZGv25qatLu3buVkZGhcePGaeXKlXryySd12WWXqaCgQI899pjy8vK0YMGCRK4bADDIeQdo586duvHGG6Nfr1q1SpK0ZMkSVVVV6aGHHlJnZ6fuvvtutbe3a+bMmdq6dasuuOCCxK0aADDoBZxzznoRXxWJRBQKhTRb8zUikGK9HAxSf/nf18Y3908veM/c+bc53jN/n9nhPaPeHv8ZwMAJ160abVE4HD7j+/rmn4IDAJyfCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYML71zEAg8GVD/8lrrk7p/jf2Xr9+Oqz73SKG24p955Je73eewYYyLgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSDEk97eG45g4vv9J75sBvvvCe+R9Pvuw9U/HPC71n3Mch7xlJyv/XOv8h5+I6Fs5fXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSnwFb1/+JP3zK1rfuQ988rq/+k9s/s6/xuY6jr/EUm66sIV3jOX/arFe+bEXz/xnsHQwRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi4Jxz1ov4qkgkolAopNmarxGBFOvlAEnhZlztPZP+00+9Z16d8H+8Z+I16f3/7j1zxZqw90zPvr96z+DcOuG6VaMtCofDSk9P73c/roAAACYIEADAhHeAtm/frptuukl5eXkKBALavHlzzPNLly5VIBCI2ebNm5eo9QIAhgjvAHV2dqqwsFDr1q3rd5958+appaUlur366qvfaJEAgKHH+zeilpWVqays7Iz7BINB5eTkxL0oAMDQl5T3gGpqapSVlaUrrrhCy5cv1+HDh/vdt6urS5FIJGYDAAx9CQ/QvHnz9PLLL6u6ulo/+9nPVFtbq7KyMvX09PS5f2VlpUKhUHTLz89P9JIAAAOQ97fgzubWW2+N/nnKlCmaOnWqJk6cqJqaGs2ZM+e0/SsqKrRq1aro15FIhAgBwHkg6R/DnjBhgjIzM9XY2Njn88FgUOnp6TEbAGDoS3qAPv30Ux0+fFi5ubnJPhQAYBDx/hbckSNHYq5mmpqatHv3bmVkZCgjI0Nr1qzRokWLlJOTo/379+uhhx7SpZdeqtLS0oQuHAAwuHkHaOfOnbrxxhujX3/5/s2SJUv0/PPPa8+ePXrppZfU3t6uvLw8zZ07Vz/5yU8UDAYTt2oAwKDHzUiBQWJ4dpb3zMHFl8Z1rB0P/8J7Zlgc39G/o2mu90x4Zv8/1oGBgZuRAgAGNAIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhI+K/kBpAcPW2HvGeyn/WfkaRjD53wnhkVSPWe+dUlb3vP/NPCld4zozbt8J5B8nEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakgIHemVd7z+y/5QLvmclXf+I9I8V3Y9F4PPf5f/GeGbVlZxJWAgtcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKfAVgWsme8/85V/8b9z5qxkvec/MuuC498y51OW6vWfqPy/wP1Bvi/8MBiSugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFAPeiILx3jP778yL61hPLH7Ne2bRRZ/FdayB7JG2a7xnan9xnffMt16q857B0MEVEADABAECAJjwClBlZaWuvfZapaWlKSsrSwsWLFBDQ0PMPseOHVN5ebkuvvhiXXTRRVq0aJHa2toSumgAwODnFaDa2lqVl5ervr5e7777rrq7uzV37lx1dnZG97n//vv11ltvaePGjaqtrdXBgwd18803J3zhAIDBzetDCFu3bo35uqqqSllZWdq1a5dmzZqlcDisX//619qwYYO+973vSZLWr1+vK6+8UvX19bruOv83KQEAQ9M3eg8oHA5LkjIyMiRJu3btUnd3t0pKSqL7TJo0SePGjVNdXd+fdunq6lIkEonZAABDX9wB6u3t1cqVKzVjxgxNnjxZktTa2qrU1FSNHj06Zt/s7Gy1trb2+fdUVlYqFApFt/z8/HiXBAAYROIOUHl5ufbu3avXXvP/uYmvqqioUDgcjm7Nzc3f6O8DAAwOcf0g6ooVK/T2229r+/btGjt2bPTxnJwcHT9+XO3t7TFXQW1tbcrJyenz7woGgwoGg/EsAwAwiHldATnntGLFCm3atEnbtm1TQUFBzPPTpk1TSkqKqquro481NDTowIEDKi4uTsyKAQBDgtcVUHl5uTZs2KAtW7YoLS0t+r5OKBTSyJEjFQqFdNddd2nVqlXKyMhQenq67rvvPhUXF/MJOABADK8APf/885Kk2bNnxzy+fv16LV26VJL085//XMOGDdOiRYvU1dWl0tJS/fKXv0zIYgEAQ0fAOeesF/FVkUhEoVBIszVfIwIp1svBGYy4ZJz3THharvfM4h9vPftOp7hn9F+9Zwa6B1r8v4tQ90v/m4pKUkbV7/2HenviOhaGnhOuWzXaonA4rPT09H73415wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBHXb0TFwDUit+/fPHsmn794YVzHWl5Q6z1zW1pbXMcayFb850zvmY+ev9p7JvPf93rPZHTUec8A5wpXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5Geo4cL73Gf+b+z71nHrn0He+ZuSM7vWcGuraeL+Kam/WbB7xnJj36Z++ZjHb/m4T2ek8AAxtXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5Geo58ssC/9X+ZsjEJK0mcde0TvWd+UTvXeybQE/CemfRkk/eMJF3WtsN7pieuIwHgCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBFwzjnrRXxVJBJRKBTSbM3XiECK9XIAAJ5OuG7VaIvC4bDS09P73Y8rIACACQIEADDhFaDKykpde+21SktLU1ZWlhYsWKCGhoaYfWbPnq1AIBCz3XPPPQldNABg8PMKUG1trcrLy1VfX693331X3d3dmjt3rjo7O2P2W7ZsmVpaWqLb2rVrE7poAMDg5/UbUbdu3RrzdVVVlbKysrRr1y7NmjUr+vioUaOUk5OTmBUCAIakb/QeUDgcliRlZGTEPP7KK68oMzNTkydPVkVFhY4ePdrv39HV1aVIJBKzAQCGPq8roK/q7e3VypUrNWPGDE2ePDn6+O23367x48crLy9Pe/bs0cMPP6yGhga9+eabff49lZWVWrNmTbzLAAAMUnH/HNDy5cv129/+Vh988IHGjh3b737btm3TnDlz1NjYqIkTJ572fFdXl7q6uqJfRyIR5efn83NAADBIfd2fA4rrCmjFihV6++23tX379jPGR5KKiookqd8ABYNBBYPBeJYBABjEvALknNN9992nTZs2qaamRgUFBWed2b17tyQpNzc3rgUCAIYmrwCVl5drw4YN2rJli9LS0tTa2ipJCoVCGjlypPbv368NGzbo+9//vi6++GLt2bNH999/v2bNmqWpU6cm5R8AADA4eb0HFAgE+nx8/fr1Wrp0qZqbm/WDH/xAe/fuVWdnp/Lz87Vw4UI9+uijZ/w+4FdxLzgAGNyS8h7Q2VqVn5+v2tpan78SAHCe4l5wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATI6wXcCrnnCTphLolZ7wYAIC3E+qW9I//nvdnwAWoo6NDkvSB3jFeCQDgm+jo6FAoFOr3+YA7W6LOsd7eXh08eFBpaWkKBAIxz0UiEeXn56u5uVnp6elGK7THeTiJ83AS5+EkzsNJA+E8OOfU0dGhvLw8DRvW/zs9A+4KaNiwYRo7duwZ90lPTz+vX2Bf4jycxHk4ifNwEufhJOvzcKYrny/xIQQAgAkCBAAwMagCFAwGtXr1agWDQeulmOI8nMR5OInzcBLn4aTBdB4G3IcQAADnh0F1BQQAGDoIEADABAECAJggQAAAE4MmQOvWrdMll1yiCy64QEVFRfr9739vvaRz7oknnlAgEIjZJk2aZL2spNu+fbtuuukm5eXlKRAIaPPmzTHPO+f0+OOPKzc3VyNHjlRJSYn27dtns9gkOtt5WLp06Wmvj3nz5tksNkkqKyt17bXXKi0tTVlZWVqwYIEaGhpi9jl27JjKy8t18cUX66KLLtKiRYvU1tZmtOLk+DrnYfbs2ae9Hu655x6jFfdtUATo9ddf16pVq7R69Wp99NFHKiwsVGlpqQ4dOmS9tHPuqquuUktLS3T74IMPrJeUdJ2dnSosLNS6dev6fH7t2rV69tln9cILL2jHjh268MILVVpaqmPHjp3jlSbX2c6DJM2bNy/m9fHqq6+ewxUmX21trcrLy1VfX693331X3d3dmjt3rjo7O6P73H///Xrrrbe0ceNG1dbW6uDBg7r55psNV514X+c8SNKyZctiXg9r1641WnE/3CAwffp0V15eHv26p6fH5eXlucrKSsNVnXurV692hYWF1sswJclt2rQp+nVvb6/LyclxTz31VPSx9vZ2FwwG3auvvmqwwnPj1PPgnHNLlixx8+fPN1mPlUOHDjlJrra21jl38t99SkqK27hxY3SfP/3pT06Sq6urs1pm0p16Hpxz7oYbbnA//OEP7Rb1NQz4K6Djx49r165dKikpiT42bNgwlZSUqK6uznBlNvbt26e8vDxNmDBBd9xxhw4cOGC9JFNNTU1qbW2NeX2EQiEVFRWdl6+PmpoaZWVl6YorrtDy5ct1+PBh6yUlVTgcliRlZGRIknbt2qXu7u6Y18OkSZM0bty4If16OPU8fOmVV15RZmamJk+erIqKCh09etRief0acDcjPdVnn32mnp4eZWdnxzyenZ2tP//5z0arslFUVKSqqipdccUVamlp0Zo1a3T99ddr7969SktLs16eidbWVknq8/Xx5XPni3nz5unmm29WQUGB9u/fr0ceeURlZWWqq6vT8OHDrZeXcL29vVq5cqVmzJihyZMnSzr5ekhNTdXo0aNj9h3Kr4e+zoMk3X777Ro/frzy8vK0Z88ePfzww2poaNCbb75puNpYAz5A+IeysrLon6dOnaqioiKNHz9eb7zxhu666y7DlWEguPXWW6N/njJliqZOnaqJEyeqpqZGc+bMMVxZcpSXl2vv3r3nxfugZ9Lfebj77rujf54yZYpyc3M1Z84c7d+/XxMnTjzXy+zTgP8WXGZmpoYPH37ap1ja2tqUk5NjtKqBYfTo0br88svV2NhovRQzX74GeH2cbsKECcrMzBySr48VK1bo7bff1vvvvx/z61tycnJ0/Phxtbe3x+w/VF8P/Z2HvhQVFUnSgHo9DPgApaamatq0aaquro4+1tvbq+rqahUXFxuuzN6RI0e0f/9+5ebmWi/FTEFBgXJycmJeH5FIRDt27DjvXx+ffvqpDh8+PKReH845rVixQps2bdK2bdtUUFAQ8/y0adOUkpIS83poaGjQgQMHhtTr4WznoS+7d++WpIH1erD+FMTX8dprr7lgMOiqqqrcH//4R3f33Xe70aNHu9bWVuulnVMPPPCAq6mpcU1NTe53v/udKykpcZmZme7QoUPWS0uqjo4O9/HHH7uPP/7YSXJPP/20+/jjj93f/vY355xzP/3pT93o0aPdli1b3J49e9z8+fNdQUGB++KLL4xXnlhnOg8dHR3uwQcfdHV1da6pqcm999577rvf/a677LLL3LFjx6yXnjDLly93oVDI1dTUuJaWluh29OjR6D733HOPGzdunNu2bZvbuXOnKy4udsXFxYarTryznYfGxkb34x//2O3cudM1NTW5LVu2uAkTJrhZs2YZrzzWoAiQc84999xzbty4cS41NdVNnz7d1dfXWy/pnFu8eLHLzc11qamp7tvf/rZbvHixa2xstF5W0r3//vtO0mnbkiVLnHMnP4r92GOPuezsbBcMBt2cOXNcQ0OD7aKT4Ezn4ejRo27u3LluzJgxLiUlxY0fP94tW7ZsyP2ftL7++SW59evXR/f54osv3L333uu+9a1vuVGjRrmFCxe6lpYWu0UnwdnOw4EDB9ysWbNcRkaGCwaD7tJLL3U/+tGPXDgctl34Kfh1DAAAEwP+PSAAwNBEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJj4f4W4/AnknuSPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, batch in enumerate(mnistTrainLoader):\n",
        "  print('Batch index: ', idx)\n",
        "  print('Batch size: ', batch[0].size())\n",
        "  print('Batch label: ', batch[1])\n",
        "  break"
      ],
      "metadata": {
        "id": "iPu3nKNozt64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (data, target) in enumerate(mnistTrainLoader):\n",
        "    print(data[0].shape)\n",
        "    print(len(data))\n",
        "    print(len(target))\n",
        "    print(target[0])\n",
        "    break"
      ],
      "metadata": {
        "id": "wv3HPgI-0SmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model\n",
        "class ResNet6(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes=10):\n",
        "        super(ResNet6, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.residual_blocks = nn.ModuleList([\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16)\n",
        "        ])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(16, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        for block in self.residual_blocks:\n",
        "            out = block(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "jbHrlhH9FJYs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the ResNet model\n",
        "model_ResNet = ResNet6(in_channels=1)\n",
        "\n",
        "# Define the training parameters\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "print_interval = 75\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ResNet.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    eval_counter = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(mnistTrainLoader, 1):\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_ResNet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        eval_counter += 1\n",
        "\n",
        "        # Print the running loss every 'print_interval' evaluations\n",
        "        if eval_counter % print_interval == 0:\n",
        "            average_loss = running_loss / print_interval\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Evaluation [{i}/{len(mnistTrainLoader)}], Loss: {average_loss}\")\n",
        "            running_loss = 0.0\n",
        "            eval_counter = 0\n",
        "\n",
        "    # Print the remaining running loss at the end of the epoch\n",
        "    if eval_counter > 0:\n",
        "        average_loss = running_loss / eval_counter\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Evaluation [{i}/{len(mnistTrainLoader)}], Loss: {average_loss}\")"
      ],
      "metadata": {
        "id": "xA5KaLRT97eU",
        "outputId": "f44ae67e-daea-4d8b-d680-2bc1af7ae3a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Evaluation [75/938], Loss: 2.0551449076334634\n",
            "Epoch [1/10], Evaluation [150/938], Loss: 1.5961734898885092\n",
            "Epoch [1/10], Evaluation [225/938], Loss: 1.2222956228256225\n",
            "Epoch [1/10], Evaluation [300/938], Loss: 0.9489353640874227\n",
            "Epoch [1/10], Evaluation [375/938], Loss: 0.7327433069547017\n",
            "Epoch [1/10], Evaluation [450/938], Loss: 0.6028642678260803\n",
            "Epoch [1/10], Evaluation [525/938], Loss: 0.4876733640829722\n",
            "Epoch [1/10], Evaluation [600/938], Loss: 0.4088536496957143\n",
            "Epoch [1/10], Evaluation [675/938], Loss: 0.3824238737424215\n",
            "Epoch [1/10], Evaluation [750/938], Loss: 0.3215906896193822\n",
            "Epoch [1/10], Evaluation [825/938], Loss: 0.2875969833135605\n",
            "Epoch [1/10], Evaluation [900/938], Loss: 0.2563775497674942\n",
            "Epoch [1/10], Evaluation [938/938], Loss: 0.23417331748887113\n",
            "Epoch [2/10], Evaluation [75/938], Loss: 0.23718696236610412\n",
            "Epoch [2/10], Evaluation [150/938], Loss: 0.22802060216665268\n",
            "Epoch [2/10], Evaluation [225/938], Loss: 0.21922427246967952\n",
            "Epoch [2/10], Evaluation [300/938], Loss: 0.1972151749332746\n",
            "Epoch [2/10], Evaluation [375/938], Loss: 0.18850418388843537\n",
            "Epoch [2/10], Evaluation [450/938], Loss: 0.19041018515825273\n",
            "Epoch [2/10], Evaluation [525/938], Loss: 0.1737770053744316\n",
            "Epoch [2/10], Evaluation [600/938], Loss: 0.1869945075114568\n",
            "Epoch [2/10], Evaluation [675/938], Loss: 0.1641600939631462\n",
            "Epoch [2/10], Evaluation [750/938], Loss: 0.1488879755139351\n",
            "Epoch [2/10], Evaluation [825/938], Loss: 0.14706385026375451\n",
            "Epoch [2/10], Evaluation [900/938], Loss: 0.14527872731288274\n",
            "Epoch [2/10], Evaluation [938/938], Loss: 0.14181090538438998\n",
            "Epoch [3/10], Evaluation [75/938], Loss: 0.13771880999207498\n",
            "Epoch [3/10], Evaluation [150/938], Loss: 0.13043221722046533\n",
            "Epoch [3/10], Evaluation [225/938], Loss: 0.1353428466618061\n",
            "Epoch [3/10], Evaluation [300/938], Loss: 0.1269360623260339\n",
            "Epoch [3/10], Evaluation [375/938], Loss: 0.12740857978661854\n",
            "Epoch [3/10], Evaluation [450/938], Loss: 0.14357283477981886\n",
            "Epoch [3/10], Evaluation [525/938], Loss: 0.12430728552242121\n",
            "Epoch [3/10], Evaluation [600/938], Loss: 0.1212064328789711\n",
            "Epoch [3/10], Evaluation [675/938], Loss: 0.13320990713934103\n",
            "Epoch [3/10], Evaluation [750/938], Loss: 0.10328673621018727\n",
            "Epoch [3/10], Evaluation [825/938], Loss: 0.11222761663297812\n",
            "Epoch [3/10], Evaluation [900/938], Loss: 0.11984212011098862\n",
            "Epoch [3/10], Evaluation [938/938], Loss: 0.11920677002911505\n",
            "Epoch [4/10], Evaluation [75/938], Loss: 0.10889658977588018\n",
            "Epoch [4/10], Evaluation [150/938], Loss: 0.09721115445097288\n",
            "Epoch [4/10], Evaluation [225/938], Loss: 0.10712419509887695\n",
            "Epoch [4/10], Evaluation [300/938], Loss: 0.10132559138039748\n",
            "Epoch [4/10], Evaluation [375/938], Loss: 0.1089576854556799\n",
            "Epoch [4/10], Evaluation [450/938], Loss: 0.09917014705638091\n",
            "Epoch [4/10], Evaluation [525/938], Loss: 0.09626918889582158\n",
            "Epoch [4/10], Evaluation [600/938], Loss: 0.09936492924888929\n",
            "Epoch [4/10], Evaluation [675/938], Loss: 0.10083106063306331\n",
            "Epoch [4/10], Evaluation [750/938], Loss: 0.10340620420873164\n",
            "Epoch [4/10], Evaluation [825/938], Loss: 0.10497209971149762\n",
            "Epoch [4/10], Evaluation [900/938], Loss: 0.1117600176980098\n",
            "Epoch [4/10], Evaluation [938/938], Loss: 0.09806981065163486\n",
            "Epoch [5/10], Evaluation [75/938], Loss: 0.09226119806369146\n",
            "Epoch [5/10], Evaluation [150/938], Loss: 0.0879696741203467\n",
            "Epoch [5/10], Evaluation [225/938], Loss: 0.0789508565266927\n",
            "Epoch [5/10], Evaluation [300/938], Loss: 0.09268464465936024\n",
            "Epoch [5/10], Evaluation [375/938], Loss: 0.0824226355055968\n",
            "Epoch [5/10], Evaluation [450/938], Loss: 0.08533445517222087\n",
            "Epoch [5/10], Evaluation [525/938], Loss: 0.09121172865231832\n",
            "Epoch [5/10], Evaluation [600/938], Loss: 0.09482705290118854\n",
            "Epoch [5/10], Evaluation [675/938], Loss: 0.08505044432977836\n",
            "Epoch [5/10], Evaluation [750/938], Loss: 0.08633009326954683\n",
            "Epoch [5/10], Evaluation [825/938], Loss: 0.09291298394401869\n",
            "Epoch [5/10], Evaluation [900/938], Loss: 0.08812149236599605\n",
            "Epoch [5/10], Evaluation [938/938], Loss: 0.10260042107026827\n",
            "Epoch [6/10], Evaluation [75/938], Loss: 0.0812574378401041\n",
            "Epoch [6/10], Evaluation [150/938], Loss: 0.0759126964211464\n",
            "Epoch [6/10], Evaluation [225/938], Loss: 0.08726255431771278\n",
            "Epoch [6/10], Evaluation [300/938], Loss: 0.08558465500672659\n",
            "Epoch [6/10], Evaluation [375/938], Loss: 0.0744454258059462\n",
            "Epoch [6/10], Evaluation [450/938], Loss: 0.06850083953390519\n",
            "Epoch [6/10], Evaluation [525/938], Loss: 0.07180232564608256\n",
            "Epoch [6/10], Evaluation [600/938], Loss: 0.06935376855234306\n",
            "Epoch [6/10], Evaluation [675/938], Loss: 0.08242169703046481\n",
            "Epoch [6/10], Evaluation [750/938], Loss: 0.08796004086732864\n",
            "Epoch [6/10], Evaluation [825/938], Loss: 0.0781925322363774\n",
            "Epoch [6/10], Evaluation [900/938], Loss: 0.0749115490540862\n",
            "Epoch [6/10], Evaluation [938/938], Loss: 0.06132240470890936\n",
            "Epoch [7/10], Evaluation [75/938], Loss: 0.06789853266129892\n",
            "Epoch [7/10], Evaluation [150/938], Loss: 0.08134908631443977\n",
            "Epoch [7/10], Evaluation [225/938], Loss: 0.08350686656932037\n",
            "Epoch [7/10], Evaluation [300/938], Loss: 0.060935793307920295\n",
            "Epoch [7/10], Evaluation [375/938], Loss: 0.06730224308868249\n",
            "Epoch [7/10], Evaluation [450/938], Loss: 0.061893648045758407\n",
            "Epoch [7/10], Evaluation [525/938], Loss: 0.06511522360146045\n",
            "Epoch [7/10], Evaluation [600/938], Loss: 0.07910721767693758\n",
            "Epoch [7/10], Evaluation [675/938], Loss: 0.07490107410897812\n",
            "Epoch [7/10], Evaluation [750/938], Loss: 0.06969507238517204\n",
            "Epoch [7/10], Evaluation [825/938], Loss: 0.06606133967017135\n",
            "Epoch [7/10], Evaluation [900/938], Loss: 0.0644562577456236\n",
            "Epoch [7/10], Evaluation [938/938], Loss: 0.07151751935874161\n",
            "Epoch [8/10], Evaluation [75/938], Loss: 0.07042669193198284\n",
            "Epoch [8/10], Evaluation [150/938], Loss: 0.06886061107118925\n",
            "Epoch [8/10], Evaluation [225/938], Loss: 0.07165647556384404\n",
            "Epoch [8/10], Evaluation [300/938], Loss: 0.062250157669186595\n",
            "Epoch [8/10], Evaluation [375/938], Loss: 0.06461310415218274\n",
            "Epoch [8/10], Evaluation [450/938], Loss: 0.06579506564885378\n",
            "Epoch [8/10], Evaluation [525/938], Loss: 0.05400078312804302\n",
            "Epoch [8/10], Evaluation [600/938], Loss: 0.07708379309624433\n",
            "Epoch [8/10], Evaluation [675/938], Loss: 0.05727402933562795\n",
            "Epoch [8/10], Evaluation [750/938], Loss: 0.06434610851109028\n",
            "Epoch [8/10], Evaluation [825/938], Loss: 0.06547789598504702\n",
            "Epoch [8/10], Evaluation [900/938], Loss: 0.05343193009495735\n",
            "Epoch [8/10], Evaluation [938/938], Loss: 0.05460490688289467\n",
            "Epoch [9/10], Evaluation [75/938], Loss: 0.06011599474896987\n",
            "Epoch [9/10], Evaluation [150/938], Loss: 0.05783972139159838\n",
            "Epoch [9/10], Evaluation [225/938], Loss: 0.048974676554401714\n",
            "Epoch [9/10], Evaluation [300/938], Loss: 0.07079291082297762\n",
            "Epoch [9/10], Evaluation [375/938], Loss: 0.06328804606571793\n",
            "Epoch [9/10], Evaluation [450/938], Loss: 0.06856940376882752\n",
            "Epoch [9/10], Evaluation [525/938], Loss: 0.05625961635261774\n",
            "Epoch [9/10], Evaluation [600/938], Loss: 0.06414342035849889\n",
            "Epoch [9/10], Evaluation [675/938], Loss: 0.057209257446229456\n",
            "Epoch [9/10], Evaluation [750/938], Loss: 0.0644010462363561\n",
            "Epoch [9/10], Evaluation [825/938], Loss: 0.06265567201500137\n",
            "Epoch [9/10], Evaluation [900/938], Loss: 0.052723188425103824\n",
            "Epoch [9/10], Evaluation [938/938], Loss: 0.06410399910160586\n",
            "Epoch [10/10], Evaluation [75/938], Loss: 0.05234540751203895\n",
            "Epoch [10/10], Evaluation [150/938], Loss: 0.05733124109605948\n",
            "Epoch [10/10], Evaluation [225/938], Loss: 0.04868161410093307\n",
            "Epoch [10/10], Evaluation [300/938], Loss: 0.061891702158997454\n",
            "Epoch [10/10], Evaluation [375/938], Loss: 0.05637256427357594\n",
            "Epoch [10/10], Evaluation [450/938], Loss: 0.06260532003516953\n",
            "Epoch [10/10], Evaluation [525/938], Loss: 0.05900855201606949\n",
            "Epoch [10/10], Evaluation [600/938], Loss: 0.05920379249379039\n",
            "Epoch [10/10], Evaluation [675/938], Loss: 0.052773435519387325\n",
            "Epoch [10/10], Evaluation [750/938], Loss: 0.056425028499215844\n",
            "Epoch [10/10], Evaluation [825/938], Loss: 0.05553434183821082\n",
            "Epoch [10/10], Evaluation [900/938], Loss: 0.05877341181660692\n",
            "Epoch [10/10], Evaluation [938/938], Loss: 0.04092261372869344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0g384giiitvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}